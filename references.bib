# Clean bib file -- https://flamingtempura.github.io/bibtex-tidy/

@misc{devlin2019bert,
	title        = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	author       = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
	year         = 2019,
	eprint       = {1810.04805},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{vaswani2017attention,
	title        = {Attention Is All You Need},
	author       = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
	year         = 2017,
	eprint       = {1706.03762},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@misc{practical_guide_to_rnn_and_lstm,
	title        = {A practical guide to RNN and LSTM in Keras | by Mohit Mayank | Towards Data Science},
	author       = {Mohit Mayank},
	year         = {},
	month        = {},
	note         = {(Accessed on 06/22/2021)},
	howpublished = {\url{https://towardsdatascience.com/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc}}
}
@misc{Guide_to_custom_recurrent_modeling,
	title        = {Guide to Custom Recurrent Modeling in Keras | by Mohit Mayank | Towards Data Science},
	author       = {Mohit Mayank},
	year         = {},
	month        = {},
	note         = {(Accessed on 06/22/2021)},
	howpublished = {\url{https://towardsdatascience.com/guide-to-custom-recurrent-modeling-in-keras-29027e3f8465}}
}
@misc{the_illustrated_bert,
	title        = {The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)},
	author       = {jalammar},
	year         = {},
	note         = {Accessed: 2021-05-06},
	howpublished = {\url{http://jalammar.github.io/illustrated-bert/}}
}
@misc{rdf_primer,
	title        = {RDF 1.1 Primer},
	author       = {w3},
	year         = {},
	note         = {Accessed: 2021-05-06},
	howpublished = {\url{https://www.w3.org/TR/rdf11-primer/}}
}
@misc{wikidata_sparql_query_helper,
	title        = {Wikidata SPARQL Query Helper},
	author       = {wikidata},
	year         = {},
	note         = {Accessed: 2021-05-06},
	howpublished = {\url{https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/Query_Helper}}
}
@misc{wikidata_api_services,
	title        = {Wikidata API Services},
	author       = {wikidata},
	year         = {},
	note         = {Accessed: 2021-05-06},
	howpublished = {\url{https://www.wikidata.org/w/api.php?action=help}}
}
@misc{guo2020survey,
	title        = {A Survey on Knowledge Graph-Based Recommender Systems},
	author       = {Qingyu Guo and Fuzhen Zhuang and Chuan Qin and Hengshu Zhu and Xing Xie and Hui Xiong and Qing He},
	year         = 2020,
	eprint       = {2003.00911},
	archiveprefix = {arXiv},
	primaryclass = {cs.IR}
}
@misc{färber2018knowledge,
	title        = {Which Knowledge Graph Is Best for Me?},
	author       = {Michael Färber and Achim Rettinger},
	year         = 2018,
	eprint       = {1809.11099},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@article{Ji_2021,
	title        = {A Survey on Knowledge Graphs: Representation, Acquisition, and Applications},
	author       = {Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
	year         = 2021,
	journal      = {IEEE Transactions on Neural Networks and Learning Systems},
	publisher    = {Institute of Electrical and Electronics Engineers (IEEE)},
	pages        = {1–21},
	doi          = {10.1109/tnnls.2021.3070843},
	issn         = {2162-2388},
	url          = {http://dx.doi.org/10.1109/TNNLS.2021.3070843}
}
@misc{lstm_understanding,
	title        = {Understanding LSTM Networks},
	author       = {Christopher Olah},
	year         = {},
	month        = {},
	note         = {(Accessed on 06/22/2021)},
	howpublished = {\url{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}}
}
@article{raffel2020exploring,
	title        = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
	author       = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang},
	year         = 2020,
	journal      = {},
	eprint       = {1910.10683},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@article{radford2018improving,
	title        = {Improving language understanding by generative pre-training},
	author       = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year         = 2018,
	journal      = {},
}
@article{radford2019language,
	title        = {Language models are unsupervised multitask learners},
	author       = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	year         = 2019,
	journal      = {OpenAI blog},
	volume       = 1,
	number       = 8,
	pages        = 9
}
@article{brown2020language,
	title        = {Language models are few-shot learners},
	author       = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.14165}
}

@misc{roberts2020knowledge,
      title={How Much Knowledge Can You Pack Into the Parameters of a Language Model?}, 
      author={Adam Roberts and Colin Raffel and Noam Shazeer},
      year={2020},
      eprint={2002.08910},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}